{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "974dce01-caea-4a2d-bec4-13a790175516",
   "metadata": {},
   "source": [
    "# Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1836d9-413a-4d63-b3b7-1b8319a6afea",
   "metadata": {},
   "source": [
    "'''\n",
    "What is Scikit-learn?\n",
    "Scikit-learn (sklearn) is a popular Python library for machine learning.\n",
    "\n",
    "It includes tools for:\n",
    "\n",
    "Classification (e.g., spam detection)\n",
    "\n",
    "Regression (e.g., price prediction)\n",
    "\n",
    "Clustering (e.g., customer segmentation)\n",
    "\n",
    "Dimensionality reduction\n",
    "\n",
    "Model evaluation and selection\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baeb4732-0965-4114-8508-e23948cd60b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\saras\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\saras\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.2.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\saras\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\saras\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\saras\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "#Install Scikit-learn\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8a839e-e594-4f84-89d3-67540d2be921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\saras\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (25.1.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e792f09-1a13-43eb-ab6e-534bd06caba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Imports from Scikit-learn\n",
    "from sklearn import datasets  # to load built-in datasets\n",
    "from sklearn.model_selection import train_test_split  # to split data\n",
    "from sklearn.preprocessing import StandardScaler  # to scale features\n",
    "from sklearn.linear_model import LinearRegression  # ML model\n",
    "from sklearn.metrics import mean_squared_error  # evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b44f3fa-0ba8-484b-b201-6101ac04e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Built-in Datasets in Scikit-learn\n",
    "from sklearn.datasets import load_iris, load_diabetes, load_digits\n",
    "#But load_boston() is deprecated now. We'll use others like load_diabetes() or load_iris()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1a4c2f9-51ca-4455-b6df-4b32c93df700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])\n",
      "Feature names: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "Data shape: (442, 10)\n",
      "Target shape: (442,)\n"
     ]
    }
   ],
   "source": [
    "#Let‚Äôs Try It ‚Äì Load a Sample Dataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Load dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# View available keys\n",
    "print(diabetes.keys())\n",
    "\n",
    "# View feature names\n",
    "print(\"Feature names:\", diabetes.feature_names)\n",
    "\n",
    "# Shape of the data\n",
    "print(\"Data shape:\", diabetes.data.shape)\n",
    "print(\"Target shape:\", diabetes.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc0230d-7783-42e8-b971-d6a6de1a87c7",
   "metadata": {},
   "source": [
    "'''\n",
    "Data Preparation in Scikit-learn\n",
    "\n",
    "We'll go through the following:\n",
    "  Splitting the dataset into training and testing,\n",
    "  Scaling the features\n",
    "\n",
    "Why Split the Data?\n",
    "To train and evaluate a model properly:\n",
    "  Training data is used to teach the model.\n",
    "  Testing data is used to check how well the model performs on unseen data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fe60353-8ade-4375-8f6b-80d420e20dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (353, 10)\n",
      "Test shape: (89, 10)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the Data using train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features (X) and Target (y)\n",
    "#data (also called X) ‚Üí The features or inputs used to predict, target (also called y) ‚Üí The output or label that we want to predict\n",
    "X = diabetes.data  #X ‚Üí Feature data (shape: (442, 10))Each row is a patient.Each column is a feature (age, BMI, BP, etc.)\n",
    "y = diabetes.target  #y ‚Üí Target values (shape: (442,)), Disease progression metric (real numbers)\n",
    "\n",
    "# Split into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "'''\n",
    "test_size=0.2 ‚Üí 20% data for testing (88 samples), 80% for training (354 samples)\n",
    "random_state=42 ‚Üí Fixes the randomness so that the same split occurs every time you run it (for reproducibility)\n",
    "Returns:\n",
    "X_train ‚Üí Feature data for training (354 √ó 10)\n",
    "X_test ‚Üí Feature data for testing (88 √ó 10)\n",
    "y_train ‚Üí Target values for training (354,)\n",
    "y_test ‚Üí Target values for testing (88,)\n",
    "'''\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape) #(Minor variation may happen due to rounding 20% of 442 = 88.4 ‚Üí rounded to 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45ce386e-e5c7-4104-87ce-42ad2b8f11ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled training data (first row): [ 1.49836523  1.06136988  0.21990201  1.13887373  0.72847289  1.05589332\n",
      " -0.82445065  0.71103773  0.54748197 -0.06144896]\n"
     ]
    }
   ],
   "source": [
    "#Feature Scaling using StandardScaler\n",
    "#Why? Features should be on the same scale, especially for ML algorithms like SVM or KNN.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform both train and test\n",
    "X_train_scaled = scaler.fit_transform(X_train)  #fit calculates the mean and std on the training data.transform uses these values to scale the training data.\n",
    "X_test_scaled = scaler.transform(X_test)  #Important: We only use transform on test data, to prevent data leakage.This ensures test data is scaled using training data‚Äôs statistics (mean and std), not its own.\n",
    "\n",
    "print(\"Scaled training data (first row):\", X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86498e79-f917-4e9a-a04b-35c15262c568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhy Should We Scale Features?\\nMany ML algorithms assume all features are on the same scale (range). If not, features with larger values can dominate the learning process.\\n\\nFor Example:\\nIf you have:\\n  age: ranges from 20‚Äì80\\n  blood pressure: ranges from 80‚Äì150\\n  serum insulin: ranges from 0.1‚Äì300\\nThe algorithm might think insulin is more important just because its numbers are larger, which is misleading.\\n\\nEspecially Important For:\\n  K-Nearest Neighbors (KNN) ‚Üí Uses distance between points\\n  Support Vector Machine (SVM) ‚Üí Uses dot product and distances\\n  Gradient Descent based models ‚Üí Better convergence\\n\\nWhat Does StandardScaler Do?\\nIt transforms the features so that each column (feature) has:\\n  Mean = 0\\n  Standard Deviation = 1\\nThis is called Z-score normalization or standardization.\\nFormula:   z=((x-Œº)/ùúé) x: original value, Œº: mean of the feature, œÉ: standard deviation\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Why Should We Scale Features?\n",
    "Many ML algorithms assume all features are on the same scale (range). If not, features with larger values can dominate the learning process.\n",
    "\n",
    "For Example:\n",
    "If you have:\n",
    "  age: ranges from 20‚Äì80\n",
    "  blood pressure: ranges from 80‚Äì150\n",
    "  serum insulin: ranges from 0.1‚Äì300\n",
    "The algorithm might think insulin is more important just because its numbers are larger, which is misleading.\n",
    "\n",
    "Especially Important For:\n",
    "  K-Nearest Neighbors (KNN) ‚Üí Uses distance between points\n",
    "  Support Vector Machine (SVM) ‚Üí Uses dot product and distances\n",
    "  Gradient Descent based models ‚Üí Better convergence\n",
    "\n",
    "What Does StandardScaler Do?\n",
    "It transforms the features so that each column (feature) has:\n",
    "  Mean = 0\n",
    "  Standard Deviation = 1\n",
    "This is called Z-score normalization or standardization.\n",
    "Formula:   z=((x-Œº)/ùúé) x: original value, Œº: mean of the feature, œÉ: standard deviation\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
